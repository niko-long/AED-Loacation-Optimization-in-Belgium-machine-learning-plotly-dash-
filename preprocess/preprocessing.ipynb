{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_files(base_dir):\n",
    "    \"\"\"\n",
    "    Read all required Parquet files from the specified base directory and return a dictionary containing all dataframes.\n",
    "\n",
    "    :param base_dir: Path to the base directory, typically the directory of the current script\n",
    "    :return: Dictionary containing all dataframes\n",
    "    \"\"\"\n",
    "    # Define the path to the data directory\n",
    "    data_dir = os.path.join(base_dir, '..', 'data')\n",
    "\n",
    "    # Define file paths\n",
    "    intervention1_path = os.path.join(data_dir, 'interventions1.parquet')\n",
    "    intervention2_path = os.path.join(data_dir, 'interventions2.parquet')\n",
    "    intervention3_path = os.path.join(data_dir, 'interventions3.parquet')\n",
    "    interventionxl1_path = os.path.join(data_dir, 'interventions_bxl.parquet.gzip')\n",
    "    interventionxl2_path = os.path.join(data_dir, 'interventions_bxl2.parquet.gzip')\n",
    "    cad_path = os.path.join(data_dir, 'cad9.parquet.gzip')\n",
    "    ambulance_path = os.path.join(data_dir, 'ambulance_locations.parquet.gzip')\n",
    "    aed_path = os.path.join(data_dir, 'aed_locations.parquet.gzip')\n",
    "    pit_path = os.path.join(data_dir, 'pit_locations.parquet.gzip')\n",
    "    mug_path = os.path.join(data_dir, 'mug_locations.parquet.gzip')\n",
    "\n",
    "    # Read all Parquet files\n",
    "    intervention1 = pd.read_parquet(intervention1_path)\n",
    "    intervention2 = pd.read_parquet(intervention2_path)\n",
    "    intervention3 = pd.read_parquet(intervention3_path)\n",
    "    interventionxl1 = pd.read_parquet(interventionxl1_path)\n",
    "    interventionxl2 = pd.read_parquet(interventionxl2_path)\n",
    "    cad = pd.read_parquet(cad_path)\n",
    "    ambulance = pd.read_parquet(ambulance_path)\n",
    "    aed = pd.read_parquet(aed_path)\n",
    "    pit = pd.read_parquet(pit_path)\n",
    "    mug = pd.read_parquet(mug_path)\n",
    "\n",
    "    return {\n",
    "        \"intervention1\": intervention1,\n",
    "        \"intervention2\": intervention2,\n",
    "        \"intervention3\": intervention3,\n",
    "        \"interventionxl1\": interventionxl1,\n",
    "        \"interventionxl2\": interventionxl2,\n",
    "        \"cad\": cad,\n",
    "        \"ambulance\": ambulance,\n",
    "        \"aed\": aed,\n",
    "        \"pit\": pit,\n",
    "        \"mug\": mug\n",
    "    }\n",
    "\n",
    "# Get the current working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Call the function to read all data\n",
    "data = read_data_files(base_dir)\n",
    "\n",
    "# Retrieve each dataframe\n",
    "intervention1 = data[\"intervention1\"]\n",
    "intervention2 = data[\"intervention2\"]\n",
    "intervention3 = data[\"intervention3\"]\n",
    "interventionxl1 = data[\"interventionxl1\"]\n",
    "interventionxl2 = data[\"interventionxl2\"]\n",
    "cad = data[\"cad\"]\n",
    "ambulance = data[\"ambulance\"]\n",
    "aed = data[\"aed\"]\n",
    "pit = data[\"pit\"]\n",
    "mug = data[\"mug\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 601881 entries, 0 to 601880\n",
      "Data columns (total 46 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   Mission ID                        601881 non-null  int64  \n",
      " 1   Service Name                      601674 non-null  object \n",
      " 2   PostalCode permanence             599280 non-null  float64\n",
      " 3   CityName permanence               599277 non-null  object \n",
      " 4   StreetName permanence             601671 non-null  object \n",
      " 5   HouseNumber permanence            35410 non-null   object \n",
      " 6   Latitude permanence               507600 non-null  float64\n",
      " 7   Longitude permanence              587382 non-null  float64\n",
      " 8   Permanence short name             601843 non-null  object \n",
      " 9   Permanence long name              601843 non-null  object \n",
      " 10  Vector type                       601881 non-null  object \n",
      " 11  EventType Firstcall               601865 non-null  object \n",
      " 12  EventLevel Firstcall              580382 non-null  object \n",
      " 13  EventType Trip                    601848 non-null  object \n",
      " 14  EventLevel Trip                   590829 non-null  object \n",
      " 15  PostalCode intervention           284 non-null     object \n",
      " 16  CityName intervention             601806 non-null  object \n",
      " 17  Latitude intervention             511158 non-null  float64\n",
      " 18  Longitude intervention            601293 non-null  float64\n",
      " 19  Province intervention             601881 non-null  object \n",
      " 20  T0                                601881 non-null  object \n",
      " 21  T1                                601881 non-null  object \n",
      " 22  T1confirmed                       474369 non-null  object \n",
      " 23  T2                                472922 non-null  object \n",
      " 24  T3                                452630 non-null  object \n",
      " 25  T4                                359878 non-null  object \n",
      " 26  T5                                343162 non-null  object \n",
      " 27  T6                                393883 non-null  object \n",
      " 28  T7                                436152 non-null  object \n",
      " 29  T9                                8910 non-null    object \n",
      " 30  Intervention time (T1Reported)    543712 non-null  float64\n",
      " 31  Intervention time (T1Confirmed)   527313 non-null  float64\n",
      " 32  Waiting time                      543712 non-null  float64\n",
      " 33  Intervention duration             473236 non-null  float64\n",
      " 34  Departure time (T1Reported)       567732 non-null  float64\n",
      " 35  Departure time (T1Confirmed)      550126 non-null  float64\n",
      " 36  Unavailable time                  10911 non-null   float64\n",
      " 37  Name destination hospital         449903 non-null  object \n",
      " 38  PostalCode destination hospital   19 non-null      object \n",
      " 39  CityName destination hospital     449946 non-null  object \n",
      " 40  StreetName destination hospital   449945 non-null  object \n",
      " 41  HouseNumber destination hospital  315 non-null     object \n",
      " 42  Calculated travelTime destinatio  385331 non-null  float64\n",
      " 43  Calculated Distance destination   385331 non-null  float64\n",
      " 44  Number of transported persons     383318 non-null  float64\n",
      " 45  Abandon reason                    75868 non-null   object \n",
      "dtypes: float64(15), int64(1), object(30)\n",
      "memory usage: 211.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#combine intervention 1,2,3\n",
    "intervention = pd.concat([intervention1, intervention2, intervention3], axis=0, ignore_index=True)\n",
    "intervention.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission ID---->491158\n",
      "Service Name---->478\n",
      "PostalCode permanence---->278\n",
      "CityName permanence---->327\n",
      "StreetName permanence---->456\n",
      "HouseNumber permanence---->23\n",
      "Latitude permanence---->430\n",
      "Longitude permanence---->719\n",
      "Permanence short name---->631\n",
      "Permanence long name---->632\n",
      "Vector type---->10\n",
      "EventType Firstcall---->141\n",
      "EventLevel Firstcall---->10\n",
      "EventType Trip---->70\n",
      "EventLevel Trip---->10\n",
      "PostalCode intervention---->96\n",
      "CityName intervention---->3508\n",
      "Latitude intervention---->102550\n",
      "Longitude intervention---->190784\n",
      "Province intervention---->10\n",
      "T0---->487985\n",
      "T1---->545684\n",
      "T1confirmed---->474276\n",
      "T2---->472774\n",
      "T3---->452478\n",
      "T4---->359776\n",
      "T5---->343052\n",
      "T6---->393773\n",
      "T7---->436071\n",
      "T9---->8910\n",
      "Intervention time (T1Reported)---->357\n",
      "Intervention time (T1Confirmed)---->356\n",
      "Waiting time---->512\n",
      "Intervention duration---->545\n",
      "Departure time (T1Reported)---->226\n",
      "Departure time (T1Confirmed)---->222\n",
      "Unavailable time---->1861\n",
      "Name destination hospital---->198\n",
      "PostalCode destination hospital---->2\n",
      "CityName destination hospital---->161\n",
      "StreetName destination hospital---->210\n",
      "HouseNumber destination hospital---->1\n",
      "Calculated travelTime destinatio---->2473\n",
      "Calculated Distance destination---->30246\n",
      "Number of transported persons---->3\n",
      "Abandon reason---->8\n"
     ]
    }
   ],
   "source": [
    "#number of unique values each feature\n",
    "features = intervention.columns\n",
    "for feature in features:\n",
    "    print(f'{feature}---->{intervention[feature].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## process T3-T0 to get the variable T3-T0\n",
    "\n",
    "# Process intervention (without specified UTC)\n",
    "# Convert time columns to datetime format, specifying the format explicitly\n",
    "intervention['T0'] = pd.to_datetime(intervention['T0'], format='%d%b%y:%H:%M:%S')\n",
    "intervention['T3'] = pd.to_datetime(intervention['T3'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "# Calculate time difference\n",
    "intervention['Time Difference'] = intervention['T3'] - intervention['T0']\n",
    "# Convert time difference to minutes\n",
    "intervention['T3-T0 in Minutes'] = intervention['Time Difference'].dt.total_seconds() / 60\n",
    "\n",
    "# Process interventionxl1 (with specified UTC)\n",
    "# Convert time columns to datetime format, handling time zones automatically to UTC\n",
    "interventionxl1['t0'] = pd.to_datetime(interventionxl1['t0'], utc=True)\n",
    "interventionxl1['t3'] = pd.to_datetime(interventionxl1['t3'], utc=True)\n",
    "\n",
    "interventionxl1['Time Difference'] = interventionxl1['t3'] - interventionxl1['t0']\n",
    "interventionxl1['T3-T0 in Minutes'] = interventionxl1['Time Difference'].dt.total_seconds() / 60\n",
    "\n",
    "# Process interventionxl2 (without specified UTC)\n",
    "# Convert time columns to datetime format, specifying the format explicitly\n",
    "interventionxl2['T0'] = pd.to_datetime(interventionxl2['T0'], format=\"%d%b%y:%H:%M:%S\")\n",
    "interventionxl2['T3'] = pd.to_datetime(interventionxl2['T3'], format=\"%d%b%y:%H:%M:%S\")\n",
    "\n",
    "interventionxl2['Time Difference'] = interventionxl2['T3'] - interventionxl2['T0']\n",
    "interventionxl2['T3-T0 in Minutes'] = interventionxl2['Time Difference'].dt.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 717528 entries, 0 to 717527\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Mission ID              717528 non-null  int64  \n",
      " 1   PostalCode permanence   714927 non-null  float64\n",
      " 2   EventType Trip          717428 non-null  object \n",
      " 3   EventLevel Trip         703419 non-null  object \n",
      " 4   Latitude intervention   626805 non-null  float64\n",
      " 5   Longitude intervention  716940 non-null  float64\n",
      " 6   T3-T0 in Minutes        538753 non-null  float64\n",
      " 7   T0                      717528 non-null  object \n",
      " 8   T3                      538753 non-null  object \n",
      " 9   Abandon reason          104902 non-null  object \n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 54.7+ MB\n",
      "[5.112496e+01 5.130626e+01 5.123878e+01 ... 5.086053e+06 5.077876e+06\n",
      " 5.090470e+05]\n"
     ]
    }
   ],
   "source": [
    "## Select features and combine intervention and interventionx1\n",
    "\n",
    "# Rename columns in xl1 and merge intervention and xl1\n",
    "interventionxl1.rename(columns={\n",
    "    'mission_id': 'Mission ID', \n",
    "    'postalcode_permanence': 'PostalCode permanence', \n",
    "    'eventtype_trip': 'EventType Trip', \n",
    "    'eventlevel_trip': 'EventLevel Trip',\n",
    "    'postalcode_intervention': 'PostalCode intervention',\n",
    "    'latitude_intervention': 'Latitude intervention',\n",
    "    'longitude_intervention': 'Longitude intervention',\n",
    "    'abandon_reason': 'Abandon reason',\n",
    "    't0': 'T0',\n",
    "    't3': 'T3'\n",
    "}, inplace=True)\n",
    "\n",
    "columns_to_use1 = [\n",
    "    'Mission ID', 'PostalCode permanence', 'EventType Trip', \n",
    "    'EventLevel Trip', 'Latitude intervention', 'Longitude intervention', \n",
    "    'T3-T0 in Minutes', 'T0', 'T3', 'Abandon reason'\n",
    "]\n",
    "\n",
    "intervention_selected = intervention[columns_to_use1]\n",
    "interventionxl1_selected = interventionxl1[columns_to_use1]\n",
    "\n",
    "intervention_combine1 = pd.concat([intervention_selected, interventionxl1_selected], axis=0, ignore_index=True)\n",
    "\n",
    "intervention_combine1.head(10)\n",
    "intervention_combine1.info()\n",
    "\n",
    "# Process EventType Trip, keep only the code of the type\n",
    "eventtype_1 = intervention_combine1['EventType Trip'].str.split(' ', expand=True)\n",
    "eventtype_1 = pd.DataFrame(eventtype_1)\n",
    "intervention_combine1.loc[:, 'EventType Trip'] = eventtype_1[0]\n",
    "\n",
    "# Function to check unique values of a specific variable\n",
    "def unique_values_of_column(series):\n",
    "    \"\"\"Return all unique values in the Series.\"\"\"\n",
    "    return series.unique()\n",
    "\n",
    "# Use the modified function to get and print unique values of the \"Latitude intervention\" column\n",
    "unique = unique_values_of_column(intervention_combine1['Latitude intervention'])\n",
    "print(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38620 entries, 0 to 38619\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Mission ID                38620 non-null  int64         \n",
      " 1   Cityname Intervention     38620 non-null  object        \n",
      " 2   Longitude intervention    38609 non-null  float64       \n",
      " 3   Latitude intervention     38609 non-null  float64       \n",
      " 4   EventType and EventLevel  36679 non-null  object        \n",
      " 5   Cityname Permanence       34320 non-null  object        \n",
      " 6   T3-T0 in Minutes          16874 non-null  float64       \n",
      " 7   T0                        38620 non-null  datetime64[ns]\n",
      " 8   T3                        16874 non-null  datetime64[ns]\n",
      " 9   Abandon reason NL         4294 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(4)\n",
      "memory usage: 2.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38620 entries, 0 to 38619\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Mission ID                38620 non-null  int64         \n",
      " 1   Cityname Intervention     38620 non-null  object        \n",
      " 2   Longitude intervention    38609 non-null  float64       \n",
      " 3   Latitude intervention     38609 non-null  float64       \n",
      " 4   EventType and EventLevel  36679 non-null  object        \n",
      " 5   Cityname Permanence       34320 non-null  object        \n",
      " 6   T3-T0 in Minutes          16874 non-null  float64       \n",
      " 7   T0                        38620 non-null  datetime64[ns]\n",
      " 8   T3                        16874 non-null  datetime64[ns]\n",
      " 9   Abandon reason            4294 non-null   object        \n",
      " 10  PostalCode permanence     34320 non-null  float64       \n",
      " 11  PostalCode intervention   38593 non-null  float64       \n",
      " 12  EventType Trip            36679 non-null  object        \n",
      " 13  EventLevel Trip           36679 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(5), int64(1), object(6)\n",
      "memory usage: 4.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38620 entries, 0 to 38619\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Mission ID              38620 non-null  int64         \n",
      " 1   PostalCode permanence   34320 non-null  float64       \n",
      " 2   EventType Trip          36679 non-null  object        \n",
      " 3   EventLevel Trip         36679 non-null  object        \n",
      " 4   Latitude intervention   38609 non-null  float64       \n",
      " 5   Longitude intervention  38609 non-null  float64       \n",
      " 6   T3-T0 in Minutes        16874 non-null  float64       \n",
      " 7   T0                      38620 non-null  datetime64[ns]\n",
      " 8   T3                      16874 non-null  datetime64[ns]\n",
      " 9   Abandon reason          4294 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(4), int64(1), object(3)\n",
      "memory usage: 2.9+ MB\n",
      "['N05' 'N01' 'N03' 'Buitendienststelling' '' 'N04' None 'N02' 'N07' 'N06'\n",
      " 'N08' 'Interventieplan']\n",
      "Mission ID ----> 30398\n",
      "Cityname Intervention ----> 231\n",
      "Longitude intervention ----> 21152\n",
      "Latitude intervention ----> 21118\n",
      "EventType and EventLevel ----> 202\n",
      "Cityname Permanence ----> 27\n",
      "T3-T0 in Minutes ----> 2748\n",
      "T0 ----> 31155\n",
      "T3 ----> 16473\n",
      "Abandon reason ----> 8\n",
      "PostalCode permanence ----> 25\n",
      "PostalCode intervention ----> 126\n",
      "EventType Trip ----> 63\n",
      "EventLevel Trip ----> 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/1354401682.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interventionxl2_selected1.loc[:, 'PostalCode permanence'] = cityname_P[0]\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/1354401682.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interventionxl2_selected1.loc[:, 'PostalCode intervention'] = cityname_i[0]\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/1354401682.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interventionxl2_selected1.loc[:, 'EventType Trip'] = event[0]\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/1354401682.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interventionxl2_selected1.loc[:, 'EventLevel Trip'] = event[1]\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/1354401682.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interventionxl2_selected1.rename(columns={'Abandon reason NL': 'Abandon reason'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Process interventionxl2\n",
    "\n",
    "# Select the required variables\n",
    "columns_to_use_xl2 = [\n",
    "    'Mission ID', 'Cityname Intervention', 'Longitude intervention', \n",
    "    'Latitude intervention', 'EventType and EventLevel', \n",
    "    'Cityname Permanence', 'T3-T0 in Minutes', 'T0', 'T3', 'Abandon reason NL'\n",
    "]\n",
    "\n",
    "interventionxl2_selected1 = interventionxl2[columns_to_use_xl2]\n",
    "\n",
    "interventionxl2_selected1.head(10)\n",
    "interventionxl2_selected1.info()\n",
    "\n",
    "# Process cityname, original format: postcode+cityname, generate new column PostalCode permanence\n",
    "cityname_P = interventionxl2_selected1['Cityname Permanence'].str.split(' ', expand=True)\n",
    "cityname_P = pd.DataFrame(cityname_P)\n",
    "cityname_P[0] = pd.to_numeric(cityname_P[0], errors='coerce', downcast=\"integer\")\n",
    "interventionxl2_selected1.loc[:, 'PostalCode permanence'] = cityname_P[0]\n",
    "\n",
    "# Process to generate new column PostalCode intervention\n",
    "cityname_i = interventionxl2_selected1['Cityname Intervention'].str.split(' ', expand=True)\n",
    "cityname_i = pd.DataFrame(cityname_i)\n",
    "cityname_i[0] = pd.to_numeric(cityname_i[0], errors='coerce', downcast=\"integer\")\n",
    "interventionxl2_selected1.loc[:, 'PostalCode intervention'] = cityname_i[0]\n",
    "\n",
    "# Process EventType and EventLevel, original format Type+Level+event\n",
    "event = interventionxl2_selected1['EventType and EventLevel'].str.split(' ', expand=True)\n",
    "event = pd.DataFrame(event)\n",
    "interventionxl2_selected1.loc[:, 'EventType Trip'] = event[0]\n",
    "interventionxl2_selected1.loc[:, 'EventLevel Trip'] = event[1]\n",
    "\n",
    "# Process abandon reason\n",
    "interventionxl2_selected1.rename(columns={'Abandon reason NL': 'Abandon reason'}, inplace=True)\n",
    "\n",
    "interventionxl2_selected1.head(10)\n",
    "interventionxl2_selected1.info()\n",
    "\n",
    "# Extract the required columns to match the previous tables and merge all tables\n",
    "columns_to_use1 = [\n",
    "    'Mission ID', 'PostalCode permanence', 'EventType Trip', 'EventLevel Trip', \n",
    "    'Latitude intervention', 'Longitude intervention', 'T3-T0 in Minutes', \n",
    "    'T0', 'T3', 'Abandon reason'\n",
    "]\n",
    "\n",
    "interventionxl2_selected2 = interventionxl2_selected1[columns_to_use1]\n",
    "\n",
    "interventionxl2_selected2.head(10)\n",
    "interventionxl2_selected2.info()\n",
    "\n",
    "# Use the modified function to get and print unique values\n",
    "unique = unique_values_of_column(interventionxl2_selected2['EventLevel Trip'])\n",
    "print(unique)\n",
    "\n",
    "# Check the number of unique values\n",
    "features = interventionxl2_selected1.columns\n",
    "for feature in features:\n",
    "    print(f'{feature} ----> {interventionxl2_selected1[feature].nunique()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 756148 entries, 0 to 756147\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Mission ID              756148 non-null  int64  \n",
      " 1   PostalCode permanence   749247 non-null  float64\n",
      " 2   EventType Trip          754107 non-null  object \n",
      " 3   EventLevel Trip         740098 non-null  object \n",
      " 4   Latitude intervention   665414 non-null  float64\n",
      " 5   Longitude intervention  755549 non-null  float64\n",
      " 6   T3-T0 in Minutes        555627 non-null  float64\n",
      " 7   T0                      756148 non-null  object \n",
      " 8   T3                      555627 non-null  object \n",
      " 9   Abandon reason          109196 non-null  object \n",
      "dtypes: float64(4), int64(1), object(5)\n",
      "memory usage: 57.7+ MB\n"
     ]
    }
   ],
   "source": [
    "## Merge the first 5 intervention tables\n",
    "intervention_all_combined = pd.concat([intervention_combine1, interventionxl2_selected2], axis=0, ignore_index=True)\n",
    "\n",
    "intervention_all_combined.head(10)\n",
    "intervention_all_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the merged table\n",
    "\n",
    "# Filter rows where EventType Trip is P003 (Cardiac arrest)\n",
    "intervention_all = intervention_all_combined[intervention_all_combined['EventType Trip'] == 'P003']\n",
    "#intervention_all = intervention_all_combined[intervention_all_combined['EventType Trip'].isin(['P003', 'P039'])]\n",
    "\n",
    "# Remove rows with abnormal PostalCode permanence values, such as postcodes longer than 4 digits (e.g., 59300)\n",
    "ids_to_remove_postcode = [50221590180, 50221620575, 50221630543, 80221550419, 80221570734]\n",
    "intervention_all = intervention_all[~intervention_all['Mission ID'].isin(ids_to_remove_postcode)]\n",
    "\n",
    "# Remove rows where EventLevel Trip values are \"Buitendienststelling\" or \"Interventieplan\"\n",
    "values_to_remove_level = ['Buitendienststelling', 'Interventieplan']\n",
    "intervention_all = intervention_all[~intervention_all['EventLevel Trip'].isin(values_to_remove_level)]\n",
    "\n",
    "# Handle inconsistent EventLevel Trip values like N1 and N01\n",
    "# Create a mapping dictionary\n",
    "replacements = {\n",
    "    'N01': 'N1',\n",
    "    'N02': 'N2',\n",
    "    'N03': 'N3',\n",
    "    'N04': 'N4',\n",
    "    'N05': 'N5',\n",
    "    'N06': 'N6',\n",
    "    'N07': 'N7',\n",
    "    'N08': 'N8',\n",
    "    'N7A': 'N7',\n",
    "    'N7B': 'N7',\n",
    "}\n",
    "intervention_all['EventLevel Trip'] = intervention_all['EventLevel Trip'].replace(replacements)\n",
    "\n",
    "# Remove empty values\n",
    "# Replace empty strings with NaN in EventLevel Trip\n",
    "intervention_all['EventLevel Trip'] = intervention_all['EventLevel Trip'].replace('', np.nan)\n",
    "\n",
    "# Specify columns to check for NaN values\n",
    "columns_to_check = intervention_all.columns.difference(['Abandon reason'])\n",
    "# Drop rows with NaN values in columns other than 'Abandon reason'\n",
    "intervention_all = intervention_all.dropna(subset=columns_to_check)\n",
    "\n",
    "# Handle duplicate Mission ID values\n",
    "# Function to extract number from a string\n",
    "def extract_number(s):\n",
    "    if len(s) > 1:  # Ensure the string is long enough to avoid indexing errors\n",
    "        try:\n",
    "            return int(s[1:])  # Try to extract and convert the number\n",
    "        except ValueError:\n",
    "            return float('inf')  # Return a large number if conversion fails\n",
    "    return float('inf')  # Return a large number if the string format is unexpected\n",
    "\n",
    "# Function to process groups of duplicate Mission IDs\n",
    "def process_group(group):\n",
    "    sorted_group = group.sort_values(by='Abandon reason', key=lambda col: col.notna(), ascending=False)\n",
    "    if sorted_group['Abandon reason'].notna().any():\n",
    "        return sorted_group.head(1)\n",
    "    sorted_group['EventLevel number'] = sorted_group['EventLevel Trip'].apply(extract_number)\n",
    "    sorted_group = sorted_group.sort_values(by='EventLevel number')\n",
    "    min_event_level = sorted_group['EventLevel number'].min()\n",
    "    duplicates = sorted_group[sorted_group['EventLevel number'] == min_event_level]\n",
    "    if len(duplicates) > 1:\n",
    "        return duplicates.sample(n=1)  # Randomly select one if there are duplicate minimum numbers\n",
    "    return duplicates.head(1)\n",
    "\n",
    "# Apply the processing function\n",
    "intervention_all = intervention_all.groupby('Mission ID').apply(process_group).reset_index(drop=True)\n",
    "intervention_all = intervention_all.drop(columns=['EventLevel number'])\n",
    "\n",
    "# Handle missing decimal points in coordinate values\n",
    "# Function to format latitude values\n",
    "def format_latitude(lat):\n",
    "    lat_str = str(lat)\n",
    "    if '.' in lat_str:\n",
    "        lat_str = lat_str.replace('.', '')  # Remove the original decimal point\n",
    "    if len(lat_str) > 2:\n",
    "        lat_str = lat_str[:2] + '.' + lat_str[2:8]\n",
    "    return float(lat_str)\n",
    "\n",
    "# Function to format longitude values\n",
    "def format_longitude(lon):\n",
    "    lon_str = str(lon)\n",
    "    if '.' in lon_str:\n",
    "        lon_str = lon_str.replace('.', '')  # Remove the original decimal point\n",
    "    if len(lon_str) > 1:\n",
    "        lon_str = lon_str[:1] + '.' + lon_str[1:5]\n",
    "    return float(lon_str)\n",
    "\n",
    "# Convert values greater than 60 in the Latitude intervention column to a two-digit number\n",
    "intervention_all['Latitude intervention'] = intervention_all['Latitude intervention'].apply(\n",
    "    lambda x: format_latitude(x) if x > 60 else x\n",
    ")\n",
    "\n",
    "# Convert values greater than 8 in the Longitude intervention column to a single-digit number\n",
    "intervention_all['Longitude intervention'] = intervention_all['Longitude intervention'].apply(\n",
    "    lambda x: format_longitude(x) if x > 8 else x\n",
    ")\n",
    "\n",
    "# Add a new target column\n",
    "intervention_all['target'] = intervention_all['Abandon reason'].apply(\n",
    "    lambda x: 1 if x in ['Overleden', 'Dood Ter Plaatse'] else 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3689 entries, 0 to 3688\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Mission ID              3689 non-null   int64  \n",
      " 1   PostalCode permanence   3689 non-null   float64\n",
      " 2   EventType Trip          3689 non-null   object \n",
      " 3   EventLevel Trip         3689 non-null   object \n",
      " 4   Latitude intervention   3689 non-null   float64\n",
      " 5   Longitude intervention  3689 non-null   float64\n",
      " 6   T3-T0 in Minutes        3689 non-null   float64\n",
      " 7   T0                      3689 non-null   object \n",
      " 8   T3                      3689 non-null   object \n",
      " 9   Abandon reason          2349 non-null   object \n",
      " 10  target                  3689 non-null   int64  \n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 317.2+ KB\n",
      "Mission ID                   0\n",
      "PostalCode permanence        0\n",
      "EventType Trip               0\n",
      "EventLevel Trip              0\n",
      "Latitude intervention        0\n",
      "Longitude intervention       0\n",
      "T3-T0 in Minutes             0\n",
      "T0                           0\n",
      "T3                           0\n",
      "Abandon reason            1340\n",
      "target                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Check for missing values\n",
    "intervention_all.info()\n",
    "\n",
    "missing_values_count = intervention_all.isnull().sum()\n",
    "print(missing_values_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to Excel\n",
    "\n",
    "# Parse datetime strings, considering time zones\n",
    "intervention_all['T0'] = pd.to_datetime(intervention_all['T0'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "intervention_all['T3'] = pd.to_datetime(intervention_all['T3'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "\n",
    "# Remove time zone information from datetime columns\n",
    "intervention_all['T0'] = intervention_all['T0'].dt.tz_localize(None)\n",
    "intervention_all['T3'] = intervention_all['T3'].dt.tz_localize(None)\n",
    "\n",
    "# export and download\n",
    "#data_dir = os.path.join(base_dir, '..', 'data')\n",
    "#combined_file_path = os.path.join(data_dir, 'intervention_all.xlsx')\n",
    "#intervention_all.to_excel(combined_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels_zip_codes = [\n",
    "    1000, 1020, 1030, 1040, 1050, 1060, 1070, 1080, 1081, 1082, 1083,\n",
    "    1090, 1100, 1110, 1120, 1130, 1140, 1150, 1160, 1170, 1180, 1190,\n",
    "    1200, 1210\n",
    "]\n",
    "\n",
    "antwerp_zip_codes = [\n",
    "        2000, 2018, 2020, 2030, 2040, 2050, 2060, 2100, 2140, 2170, 2180,\n",
    "        2600, 2610\n",
    "    ]\n",
    "\n",
    "liege_zip_codes = [\n",
    "    4000, 4020, 4030, 4031, 4032, 4040, 4041,\n",
    "    4042, 4050, 4051, 4100, 4101, 4102, 4120,\n",
    "    4121, 4140, 4141, 4150, 4151, 4160, 4161,\n",
    "    4170, 4171, 4180, 4181, 4190, 4210, 4211,\n",
    "    4212, 4217, 4218, 4219, 4280, 4287\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels_intervention_data = intervention_all[intervention_all['PostalCode permanence'].isin(brussels_zip_codes)]\n",
    "antwerp_intervention_data = intervention_all[intervention_all['PostalCode permanence'].isin(antwerp_zip_codes)]\n",
    "liege_intervention_data = intervention_all[intervention_all['PostalCode permanence'].isin(liege_zip_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/3571673923.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  brussels_intervention_data['Month'] = brussels_intervention_data['T0'].dt.to_period('M')\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/3571673923.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antwerp_intervention_data['Month'] = antwerp_intervention_data['T0'].dt.to_period('M')\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/3571673923.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liege_intervention_data['Month'] = liege_intervention_data['T0'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "# Extract month information\n",
    "brussels_intervention_data['Month'] = brussels_intervention_data['T0'].dt.to_period('M')\n",
    "antwerp_intervention_data['Month'] = antwerp_intervention_data['T0'].dt.to_period('M')\n",
    "liege_intervention_data['Month'] = liege_intervention_data['T0'].dt.to_period('M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Brussels:\n",
      "Total Cases: 237\n",
      "Deaths: 124\n",
      "Survival Rate: 47.68%\n",
      "Death Rate: 52.32%\n",
      "\n",
      "Statistics for Antwerp:\n",
      "Total Cases: 420\n",
      "Deaths: 210\n",
      "Survival Rate: 50.00%\n",
      "Death Rate: 50.00%\n",
      "\n",
      "Statistics for Liege:\n",
      "Total Cases: 336\n",
      "Deaths: 207\n",
      "Survival Rate: 38.39%\n",
      "Death Rate: 61.61%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate and display statistics\n",
    "def display_statistics(data, city_name):\n",
    "    total_cases = len(data)\n",
    "    deaths = data['target'].sum()\n",
    "    survival_rate = ((total_cases - deaths) / total_cases) * 100\n",
    "    death_rate = (deaths / total_cases) * 100\n",
    "    \n",
    "    print(f\"Statistics for {city_name}:\")\n",
    "    print(f\"Total Cases: {total_cases}\")\n",
    "    print(f\"Deaths: {deaths}\")\n",
    "    print(f\"Survival Rate: {survival_rate:.2f}%\")\n",
    "    print(f\"Death Rate: {death_rate:.2f}%\")\n",
    "    print()\n",
    "\n",
    "# Display statistics for each city\n",
    "display_statistics(brussels_intervention_data, \"Brussels\")\n",
    "display_statistics(antwerp_intervention_data, \"Antwerp\")\n",
    "display_statistics(liege_intervention_data, \"Liege\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate statistics by month\n",
    "def calculate_statistics(data, city_name):\n",
    "    grouped_data = data.groupby('Month')\n",
    "    stats_list = []\n",
    "\n",
    "    for month, group in grouped_data:\n",
    "        total_cases = len(group)\n",
    "        deaths = group['target'].sum()\n",
    "        death_rate = (deaths / total_cases) * 100\n",
    "\n",
    "        stats_list.append({\n",
    "            'City': city_name,\n",
    "            'Month': month,\n",
    "            'Total Cases': total_cases,\n",
    "            'Deaths': deaths,\n",
    "            'Death Rate (%)': death_rate\n",
    "        })\n",
    "\n",
    "    return stats_list\n",
    "\n",
    "# Calculate statistics for each city\n",
    "brussels_stats = calculate_statistics(brussels_intervention_data, \"Brussels\")\n",
    "antwerp_stats = calculate_statistics(antwerp_intervention_data, \"Antwerp\")\n",
    "liege_stats = calculate_statistics(liege_intervention_data, \"Liege\")\n",
    "\n",
    "# Combine all statistics into a single DataFrame\n",
    "all_stats = brussels_stats + antwerp_stats + liege_stats\n",
    "all_stats = pd.DataFrame(all_stats)\n",
    "\n",
    "# Save the statistics to a file\n",
    "#combined_file_path = os.path.join(data_dir, 'all_stats.xlsx')\n",
    "#all_stats.to_excel(combined_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_file_path = os.path.join(data_dir, 'brussels_intervention_data.xlsx')\n",
    "#brussels_intervention_data.to_excel(combined_file_path, index=False)\n",
    "\n",
    "#combined_file_path = os.path.join(data_dir, 'antwerp_intervention_data.xlsx')\n",
    "#antwerp_intervention_data.to_excel(combined_file_path, index=False)\n",
    "\n",
    "#combined_file_path = os.path.join(data_dir, 'liege_intervention_data.xlsx')\n",
    "#liege_intervention_data.to_excel(combined_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/157082825.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  brussels_intervention_data['city'] = 'Brussels'\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/157082825.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antwerp_intervention_data['city'] = 'Antwerp'\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/157082825.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liege_intervention_data['city'] = 'Liege'\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'city'\n",
    "brussels_intervention_data['city'] = 'Brussels'\n",
    "antwerp_intervention_data['city'] = 'Antwerp'\n",
    "liege_intervention_data['city'] = 'Liege'\n",
    "\n",
    "# Combine DataFrames\n",
    "citycombined_data = pd.concat([brussels_intervention_data, antwerp_intervention_data, liege_intervention_data], ignore_index=True)\n",
    "\n",
    "# Export the combined DataFrame to a new Excel file\n",
    "#combined_file_path = '/Users/zenghui/Downloads/citycombined_intervention_data.xlsx'\n",
    "#citycombined_data.to_excel(combined_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AED filering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     id type              address  number  postal_code  \\\n",
      "0           0   13.0  AED  Blvd. Fr. Roosevelt    24.0       7060.0   \n",
      "1          13   95.0  AED          Peperstraat     2.0       3300.0   \n",
      "2          17  100.0  AED   Rue Pietro Ferrero     5.0       6700.0   \n",
      "3          19  102.0  AED          Nieuwe Weg      1.0       2070.0   \n",
      "4          21  115.0  AED        Gemeenteplein     1.0       3798.0   \n",
      "\n",
      "             municipality        province  \\\n",
      "0                SOIGNIES         Hainaut   \n",
      "1                  TIENEN  Vlaams-Brabant   \n",
      "2                   ARLON      Luxembourg   \n",
      "3             ZWIJNDRECHT       Antwerpen   \n",
      "4  Voeren  s Gravenvoeren         Limburg   \n",
      "\n",
      "                                    location public available hours  \\\n",
      "0                                        NaN    yes       NaN   NaN   \n",
      "1        Peperstraat 2, 3300 Tienen, Belgium    yes       NaN   NaN   \n",
      "2  Rue Pietro Ferrero 5, 6700 Arlon, Belgium     no       NaN   NaN   \n",
      "3    Nieuwe Weg 1, 2070 Zwijndrecht, Belgium    yes       NaN   NaN   \n",
      "4      Gemeenteplein 1, 3798 Voeren, Belgium    yes       NaN   NaN   \n",
      "\n",
      "                    full_address  latitude  longitude  \n",
      "0  Blvd. Fr. Roosevelt, 24, 7060       NaN        NaN  \n",
      "1           Peperstraat, 2, 3300  50.80682    4.93739  \n",
      "2    Rue Pietro Ferrero, 5, 6700  49.67355    5.82046  \n",
      "3           Nieuwe Weg , 1, 2070  51.24335    4.32532  \n",
      "4         Gemeenteplein, 1, 3798  50.75949    5.75978  \n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "# Define the path to the data directory\n",
    "data_dir = os.path.join(base_dir, '..', 'data')\n",
    "\n",
    "# Define the path to the aed_location.xlsx file\n",
    "aed_location = os.path.join(data_dir, 'AED_locations.xlsx')\n",
    "\n",
    "# Read the aed_location.xlsx file\n",
    "aed_location = pd.read_excel(aed_location)\n",
    "\n",
    "# Verify the contents\n",
    "print(aed_location.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5519 entries, 1 to 8078\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    5519 non-null   int64  \n",
      " 1   id            5518 non-null   float64\n",
      " 2   type          5519 non-null   object \n",
      " 3   address       5519 non-null   object \n",
      " 4   number        4880 non-null   float64\n",
      " 5   postal_code   5519 non-null   float64\n",
      " 6   municipality  5477 non-null   object \n",
      " 7   province      5516 non-null   object \n",
      " 8   location      5519 non-null   object \n",
      " 9   public        5519 non-null   object \n",
      " 10  available     2920 non-null   object \n",
      " 11  hours         708 non-null    object \n",
      " 12  full_address  5519 non-null   object \n",
      " 13  latitude      5519 non-null   float64\n",
      " 14  longitude     5519 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 689.9+ KB\n"
     ]
    }
   ],
   "source": [
    "## filter longitude and latitude\n",
    "NORTH = 51.51\n",
    "SOUTH = 49.50\n",
    "EAST = 6.40\n",
    "WEST = 2.54\n",
    "LONG_MIN = 2.4493560308402667\n",
    "LONG_MAX = 4.020383765257329\n",
    "\n",
    "aed_locationb = aed_location[\n",
    "    (aed_location['latitude'] <= NORTH) &\n",
    "    (aed_location['latitude'] >= SOUTH) &\n",
    "    (aed_location['longitude'] <= EAST) &\n",
    "    (aed_location['longitude'] >= WEST) &\n",
    "    ~((aed_location['longitude'] > LONG_MIN) & (aed_location['longitude'] < LONG_MAX))\n",
    "]\n",
    "\n",
    "aed_locationb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels_aed_data = aed_locationb[aed_locationb['postal_code'].isin(brussels_zip_codes)]\n",
    "antwerp_aed_data = aed_locationb[aed_locationb['postal_code'].isin(antwerp_zip_codes)]\n",
    "liege_aed_data = aed_locationb[aed_locationb['postal_code'].isin(liege_zip_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/3636270512.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  brussels_aed_data['city'] = 'Brussels'\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/3636270512.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antwerp_aed_data['city'] = 'Antwerp'\n",
      "/var/folders/dr/0j9y6x3n3nv4s_4ssbwb3g240000gn/T/ipykernel_90634/3636270512.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  liege_aed_data['city'] = 'Liege'\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'city'\n",
    "brussels_aed_data['city'] = 'Brussels'\n",
    "antwerp_aed_data['city'] = 'Antwerp'\n",
    "liege_aed_data['city'] = 'Liege'\n",
    "\n",
    "# Combine DataFrames\n",
    "cityaed_data = pd.concat([brussels_aed_data, antwerp_aed_data, liege_aed_data], ignore_index=True)\n",
    "\n",
    "# Export the combined DataFrame to a new Excel file\n",
    "#cityaed_path = os.path.join(data_dir, 'cityaed_data.xlsx')\n",
    "#cityaed_data.to_excel(cityaed_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
